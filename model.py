import torch.nn as nn
import torch.nn.functional as F


class ClassifierNetworkPhi(nn.Module):
    def __init__(self):
        super(ClassifierNetworkPhi, self).__init__()
        self.conv1 = nn.Conv2d(3, 96, 3)
        self.conv2 = nn.Conv2d(96, 96, 3)
        self.conv3 = nn.Conv2d(96, 96, 3, stride=2)
        self.conv4 = nn.Conv2d(96, 192, 3)
        self.conv5 = nn.Conv2d(192, 192, 3)
        self.conv6 = nn.Conv2d(192, 192, 3, stride=2)
        self.conv7 = nn.Conv2d(192, 192, 3)
        self.conv8 = nn.Conv2d(192, 192, 1)
        self.conv9 = nn.Conv2d(192, 10, 1)
        self.fc1 = nn.Linear(40, 1000)
        self.fc2 = nn.Linear(1000, 1000)
        self.fc3 = nn.Linear(1000, 2)
        self.LogSoftMax = nn.LogSoftmax(dim=1)
        self.af = F.relu

    def forward(self, x):
        h = self.conv1(x)
        h = self.af(h)
        h = self.conv2(h)
        h = self.af(h)
        h = self.conv3(h)
        h = self.af(h)
        h = self.conv4(h)
        h = self.af(h)
        h = self.conv5(h)
        h = self.af(h)
        h = self.conv6(h)
        h = self.af(h)
        h = self.conv7(h)
        h = self.af(h)
        h = self.conv8(h)
        h = self.af(h)
        h = self.conv9(h)
        h = self.af(h)
        h = h.view(-1, 10 * 2 * 2)
        h = self.fc1(h)
        h = self.af(h)
        h = self.fc2(h)
        h = self.af(h)
        h = self.fc3(h)
        return self.LogSoftMax(h)


class ClassifierNetworkD(nn.Module):
    def __init__(self):
        super(ClassifierNetworkD, self).__init__()
        self.conv1 = nn.Conv2d(3, 96, 3)
        self.conv2 = nn.Conv2d(96, 96, 3)
        self.conv3 = nn.Conv2d(96, 96, 3, stride=2)
        self.conv4 = nn.Conv2d(96, 192, 3)
        self.conv5 = nn.Conv2d(192, 192, 3)
        self.conv6 = nn.Conv2d(192, 192, 3, stride=2)
        self.conv7 = nn.Conv2d(192, 192, 3)
        self.conv8 = nn.Conv2d(192, 192, 1)
        self.conv9 = nn.Conv2d(192, 10, 1)

        self.fc1 = nn.Linear(40, 1000)
        self.fc2 = nn.Linear(1000, 1000)
        self.fc3 = nn.Linear(1000, 2)
        self.LogSoftMax = nn.LogSoftmax(dim=1)
        self.af = F.relu

    def forward(self, x):
        h = self.conv1(x)
        h = self.af(h)
        h = self.conv2(h)
        h = self.af(h)
        h = self.conv3(h)
        h = self.af(h)
        h = self.conv4(h)
        h = self.af(h)
        h = self.conv5(h)
        h = self.af(h)
        h = self.conv6(h)
        h = self.af(h)
        h = self.conv7(h)
        h = self.af(h)
        h = self.conv8(h)
        h = self.af(h)
        h = self.conv9(h)
        h = self.af(h)
        h = h.view(-1, 10 * 2 * 2)
        h = self.fc1(h)
        h = self.af(h)
        h = self.fc2(h)
        h = self.af(h)
        h = self.fc3(h)
        return self.LogSoftMax(h)
